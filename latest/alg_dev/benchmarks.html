<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmark Suite · DiffEq Developer Documentation</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/styles/default.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Ubuntu+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script></head><body><nav class="toc"><h1>DiffEq Developer Documentation</h1><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">Contributor Guide</span><ul><li><a class="toctext" href="../contributing/ecosystem_overview.html">Ecosystem Overview</a></li><li><a class="toctext" href="../contributing/adding_algorithms.html">Adding Algorithms</a></li><li><a class="toctext" href="../contributing/defining_problems.html">Developing A New Problem</a></li><li><a class="toctext" href="../contributing/diffeq_internals.html">The DiffEq Internals</a></li></ul></li><li><span class="toctext">Algorithm Development Tools</span><ul><li><a class="toctext" href="test_problems.html">-</a></li><li><a class="toctext" href="convergence.html">Convergence Simulations</a></li><li class="current"><a class="toctext" href="benchmarks.html">Benchmark Suite</a><ul class="internal"></ul></li><li><a class="toctext" href="approximate_error.html">-</a></li></ul></li><li><span class="toctext">Internal Documentation</span><ul><li><a class="toctext" href="../internals/fem_tools.html">Internal Finite Element Tools</a></li><li><a class="toctext" href="../internals/extras.html">Extra Functions</a></li><li><a class="toctext" href="../internals/solver_helpers.html">Solver Extras</a></li><li><a class="toctext" href="../internals/notes_on_algorithms.html">Notes on Algorithms</a></li><li><a class="toctext" href="../internals/tableaus.html">ODE Tableaus</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Algorithm Development Tools</li><li><a href="benchmarks.html">Benchmark Suite</a></li></ul><a class="edit-page" href="https://github.com/JuliaDiffEq/DiffEqDevDocs.jl/tree/fc67b0f884280eb2d263b14cc9b4880f3619c54f/docs/src/alg_dev/benchmarks.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h1><a class="nav-anchor" id="Benchmark-Suite-1" href="#Benchmark-Suite-1">Benchmark Suite</a></h1><p>DiffernetialEquations.jl provides a benchmarking suite to be able to test the difference in error, speed, and efficiency between algorithms. DifferentialEquations.jl includes current benchmarking notebooks to help users understand the performance of the methods. These benchmarking notebooks use the included benchmarking suite. There are two parts to the benchmarking suite: shootouts and work-precision. The <code>Shootout</code> tests methods head-to-head for timing and error on the same problem. A <code>WorkPrecision</code> draws a work-precision diagram for the algorithms in question on the chosen problem.</p><h3><a class="nav-anchor" id="Using-the-Benchmarking-Notebooks-1" href="#Using-the-Benchmarking-Notebooks-1">Using the Benchmarking Notebooks</a></h3><p>To use the benchmarking notebooks, IJulia is required. The commands are as follows:</p><pre><code class="language-julia">using IJulia
notebook(dir = Pkg.dir(&quot;DifferentialEquations&quot;)*&quot;/benchmarks&quot;)</code></pre><h3><a class="nav-anchor" id="Shootout-1" href="#Shootout-1">Shootout</a></h3><p>A shootout is where you compare between algorithms. For example, so see how different Runge-Kutta algorithms fair against each other, one can define a setup which is a dictionary of Symbols to Any, where the symbol is the keyword argument. Then you call <code>ode_shootout</code> on that setup. The code is as follows:</p><pre><code class="language-julia">tspan = [0,10]
setups = [Dict(:alg=&gt;:DP5)
          Dict(:abstol=&gt;1e-3,:reltol=&gt;1e-6,:alg=&gt;:ode45) # Fix ODE to be normal
          Dict(:alg=&gt;:dopri5)]
prob = DifferentialEquations.prob_ode_large2Dlinear
names = [&quot;DifferentialEquations&quot;;&quot;ODE&quot;;&quot;ODEInterface&quot;]
shoot = ode_shootout(prob,tspan,setups;dt=1/2^(10),names=names)</code></pre><p>Note that keyword arguments applied to ode_shootout are applie dot every run, so in this example every run has the same starting timestep.  Here we explicitly chose names. If you don&#39;t, then the algorithm name is the default. This returns a Shootout type where which holds the times it took for each algorithm and the errors. Using these, it calculates the efficiency defnied as 1/(error*time), i.e. if the error is low or the run was quick then it&#39;s efficient. <code>print(shoot)</code> will show all of this information, and <code>plot(shoot)</code> will show the efficiencies of the algorithms in comparison to each other.</p><p>For every benchmark function there is a special keyword <code>numruns</code> which controls the number of runs used in the time estimate. To be more precise, these functions by default run the algorithm 20 times on the problem and take the average time. This amount can be increased and decreased as needed.</p><p>A ShootoutSet is a where you define a vector of probs and tspans and run a shootout on each of these values.</p><h3><a class="nav-anchor" id="WorkPrecision-1" href="#WorkPrecision-1">WorkPrecision</a></h3><p>A WorkPrecision calculates the necessary componnets of a work-precision plot. This shows how time scales with the user chosen tolerances on a given problem. To make a WorkPrecision, you give it a vector of absolute and relative tolerances:</p><pre><code class="language-julia">abstols = 1./10.^(3:10)
reltols = 1./10.^(3:10)
wp = ode_workprecision(prob,tspan,abstols,reltols;alg=:DP5,name=&quot;Dormand-Prince 4/5&quot;)</code></pre><p>If we want to plot many WorkPrecisions together in order to compare between algorithms, you can make a WorkPrecisionSet. To do so, you pass the setups into the function as well:</p><pre><code class="language-julia">wp_set = ode_workprecision_set(prob,tspan,abstols,reltols,setups;dt=1/2^4,numruns=2)
setups = [Dict(:alg=&gt;:RK4);Dict(:alg=&gt;:Euler);Dict(:alg=&gt;:BS3);
          Dict(:alg=&gt;:Midpoint);Dict(:alg=&gt;:BS5);Dict(:alg=&gt;:DP5)]
wp_set = ode_workprecision_set(prob,tspan,abstols,reltols,setups;dt=1/2^4,numruns=2)</code></pre><p>Both of these types have a plot recipe to produce a work-precision diagram, and a print which will show some relevant information.</p><footer><hr/><a class="previous" href="convergence.html"><span class="direction">Previous</span><span class="title">Convergence Simulations</span></a><a class="next" href="approximate_error.html"><span class="direction">Next</span><span class="title">-</span></a></footer></article></body></html>
